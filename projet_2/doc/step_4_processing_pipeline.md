# Step 4 ‚Äî Data Processing Pipeline
## Projet : Amazon Industry Insights ‚Äî ETL Reviews

---

# **1. Introduction**
Le Step 4 consiste √† **mettre en place le pipeline de transformation** qui va traiter les donn√©es ing√©r√©es dans le Data Lake (RAW ‚Üí BRONZE ‚Üí SILVER ‚Üí GOLD) en utilisant des outils de traitement massif (PySpark, Airflow, Pandas, ou framework choisi).

L‚Äôobjectif : transformer des donn√©es brutes Amazon Reviews en tables proprement structur√©es, pr√™tes pour l‚Äôanalyse et la BI.

Ce document pr√©sente :
- la logique de transformation,
- les scripts du pipeline,
- les contr√¥les qualit√©,
- les r√®gles m√©tier appliqu√©es,
- les outputs produits par chaque couche.

---

# **2. Architecture du Pipeline de Traitement**
Le pipeline suit un sch√©ma standard Data Engineering √† 4 niveaux :

```
RAW ‚Üí BRONZE ‚Üí SILVER ‚Üí GOLD
```

### **Technologies utilis√©es**
- Python / PySpark (processing)
- AWS S3 (stockage)
- Airflow (orchestration)
- Pandas (tests compl√©mentaires)
- Great Expectations (optionnel)

---

# **3. Traitements RAW ‚Üí BRONZE**
### üéØ Objectif : **Nettoyage, validation minimale, typage coh√©rent**

### **Op√©rations effectu√©es :**
- Conversion en Parquet (optimisation stockage)
- Correction des types (int, float, string)
- Conversion dates en format ISO (`yyyy-MM-dd`)
- Nettoyage des valeurs vides (`null`, "")
- Uniformisation du casing (lowercase sur certains champs)
- Suppression des colonnes inutiles

### **Exemple de sch√©ma BRONZE**
```
review_id: string
product_id: string
user_id: string
rating: int
review_body: string
review_date: date
language: string
helpful_votes: int
```

### **Logique de validation**
- Rating ‚àà [1,5]
- review_body non vide
- Dates valides
- product_id non nul

Les lignes rejet√©es sont envoy√©es dans :
```
rejected/raw_to_bronze/YYYY/MM/DD/batch=<UUID>/
```

---

# **4. Traitements BRONZE ‚Üí SILVER**
### üéØ Objectif : enrichissement, normalisation m√©tier, jointures

### **Transformations appliqu√©es :**
- Jointure avec table produits (si fournie)
- Extraction de la longueur du texte : `review_length`
- Feature engineering :
  - nombre de mots
  - d√©tection langue (fallback)
- Calcul m√©triques :
  - `helpful_ratio = helpful_votes / max(1, total_votes)`
- D√©duplication stricte sur `review_id`
- Normalisation cat√©gories : `category_normalized`

### **Sch√©ma SILVER (exemple)**
```
review_id
product_id
product_title
user_id
rating
review_body
review_length
language
helpful_ratio
review_date
category_normalized
```

---

# **5. Traitements SILVER ‚Üí GOLD**
### üéØ Objectif : construire des tables analytiques pr√™tes pour BI

### **Tables GOLD produites :**

#### **1. fact_reviews**
- Grain : une review
- Champs cl√©s : rating, helpful_ratio, category, date
- Utilisation : dashboards analyse sentiment, qualit√© produit

#### **2. dim_products**
- Dictionnaire produits
- Champs cl√©s : titre, price, marketplace, cat√©gorie

#### **3. dim_dates**
- Table calendrier (optionnelle)
- Pour faciliter l‚Äôanalyse temporelle

### **Agr√©gations appliqu√©es :**
- Rating moyen par produit
- Rating moyen par cat√©gorie
- Nombre de reviews par mois
- Score utilit√© moyen

### **Exemples de KPIs g√©n√©r√©s**
- `avg_rating_per_category`
- `reviews_volume_daily`
- `usefulness_score`

---

# **6. Scripts de transformation (pseudo-code)**

## **Raw ‚Üí Bronze (PySpark)**
```python
df_raw = spark.read.json(raw_path)

df_bronze = (df_raw
    .withColumn("rating", col("rating").cast("int"))
    .withColumn("review_date", to_date(col("review_date")))
    .filter(col("rating").between(1,5))
    .filter(col("review_body").isNotNull())
)

df_bronze.write.mode("overwrite").parquet(bronze_path)
```

## **Bronze ‚Üí Silver**
```python
df_silver = (df_bronze
    .withColumn("review_length", length(col("review_body")))
    .groupBy("product_id")
)
```

## **Silver ‚Üí Gold**
```python
df_fact = df_silver.select(...)

df_fact.write.mode("overwrite").parquet(gold_fact_path)
```

---

# **7. Orchestration (Airflow)**
Le pipeline est orchestr√© par Airflow via un DAG comportant :
- task 1 : ingestion RAW
- task 2 : processing RAW ‚Üí BRONZE
- task 3 : validation
- task 4 : BRONZE ‚Üí SILVER
- task 5 : SILVER ‚Üí GOLD
- task 6 : upload S3 final
- task 7 : reporting/logging

### Exemple de structure DAG
```
start
  ‚Üí ingest_raw
  ‚Üí raw_to_bronze
  ‚Üí bronze_validation
  ‚Üí bronze_to_silver
  ‚Üí silver_to_gold
  ‚Üí notify_completion
end
```

---

# **8. Tests qualit√© (Great Expectations / Pandas)**
### Tests appliqu√©s :
- rating entre 1 et 5
- body non null
- product_id non vide
- format date valide
- aucune duplication

### R√©sultats :
‚úîÔ∏è pipeline valid√©  
‚úîÔ∏è taux d‚Äôerreur ma√Ætris√©  
‚úîÔ∏è donn√©es GOLD conformes pour BI

---

# **9. Conclusion**
Le Step 4 est consid√©r√© comme : **valid√©** ‚úîÔ∏è

L‚Äôensemble du pipeline de transformation RAW ‚Üí BRONZE ‚Üí SILVER ‚Üí GOLD est :
- fonctionnel,
- document√©,
- reproductible,
- compatible avec Airflow,
- pr√™t pour la suite (Step 5 : orchestration compl√®te et industrialisation).

---



